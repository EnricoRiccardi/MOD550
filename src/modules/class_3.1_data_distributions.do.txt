!split
======= Statistics =======

!bblock Definition
Statistics is the science of acquiring and utilizing data
!eblock

!bpop
* It comprises tools for data collection, summarization, and interpretation.

* The aim is identifying the underlying structure, trends, and relationships inherent in the data.

* Is it all statistics then? Yes.

* _Numbers to data, data to information_
!epop



!split
===== Data properties =====
Before we talk about machine learning, we need to refresh some terminology.

!bpop
!bblock Population
The universe of all possible outcomes and events.
!eblock

!bblock Sample
A finite subset extracted from the population.
!eblock

!bblock Exhaustivity
The samples covered the population spectra.
!eblock

!bblock Representativity
The population is properly described by the samples.
!eblock
!epop


!split
===== Big data =====
We speak of big data when dataset are very large: i.e. many instances and features
Models have thus a large set of parameters (and often no one has a clue anymore of what is going on).

!bpop
* Volume of data
* Variety different types of data sources with different length and scale.
* Frequency of data generation
!epop


!split
===== Sampling =====

Samples shall have no bias (to be randomly selected). If not, the bias has to be corrected for.
!bpop
!bblock Cycle of data
o Data is collected
o Checked upon
o Some modelling
o Analysis and visualization
!eblock
!epop

FIGURE: [../figures/circle, width=600 frac=0.33]

 


!split
===== Data quality =====

o Data has to be acquired and integrated
o Data are passed to a quality analysis and control
o Data cleaning, consistency check. Most of time goes here

 
FIGURE: [../figures/decide, width=600 frac=0.3]


!split
===== Preliminary Modeling =====

!bblock Main tasks:
o Hunt for redundancy
o Reduce dimensionality
o AnOmAlIes removal
!eblock

* Descriptive modeling (unsupervised learning)

* Predictive modeling (supervised learning)

* The model can be used to guide data acquisition (risky!)
 
 

!split
===== Visualization and reporting =====
* The data has to be condensed into a visualization to provide input for decisions.
* Depending on the goal, very very different visualizations are possible.
* Use a model to indicate what is undersampled or oversampled.



!bblock Summarizing and visualizing data as a starting point for more analysis later on.

* Computing summary statistics (e.g. means and variance)
* Determining conditional probabilities of cause+effect relationships
* Calculating correlation and rank correlation coefficient between two variables
* Visualizing univariate, bivariate and multivariate data
* ...

!eblock


!split
===== Exploratory data analysis =====

!bblock Summarizing and visualizing data as a starting point for more analysis later on.
* ...
* Estimating probability coverage levels for different distributions
* Analyzing behaviour of normal distributions
* Calculating confidence interval and sampling distribution for the mean
* Testing for significance of difference in means
* Comparing two different distributions for statistical equivalence
* Developing a nonparametric regression model from given data
* Reducing data dimensionality  
* Grouping data   

!eblock


!split
===== Random Variables =====
* A random variable is a real valued function that assigns a value to each outcome in the sample space
* A random variable (RV) can be either discrete or continuous
  * Discrete RV
  * Continuous RV

\pause

* The probability mass function (PMF),P, of a discrete RV, X, denotes the probability that the RV is equal to a specified value, a.
p(a) = p(X = a)

\pause

* The cumulative distribution function (CDF), F, denotes the sum
!bt
$ F(a) = P(X\leq a) = \sum_{0}^{a} f(x) dx $
!et


!split
===== Random Variables =====
FIGURE: [../figures/cdf, width=600 frac=1.1]
 
!split
===== Sampling =====
* What are the effective sampling strategies? (Wind turbine example)

* Solar Panels to determine the efficiency of the source (Usage patterns, energy production forecast)

* Drilling (penetration rate)

* Corrosion extension

* Concrete Rigidity

* etc



 

!split
===== Wind turbine example example =====

FIGURE: [../figures/wind, width=600 frac=1.1]

 


!split
===== Sampling approaches =====

!bblock Experimental design
Grid, parallel, series.
!eblock

\pause

!bblock Sampling without replacement
 SPR (single point representation).
!eblock


\pause

!bblock Sampling with replacement
 The number of the members of the population does not change.
!eblock






!split
======= Univariate statistics =======

* Easy to displaying data:
  * histogram
  * frequency plots
  * cumulative

\pause

* Measures of Location
  * Mean, median, mode
  * Quartiles, Percentiles, Quantiles

\pause

* Measure of Dispersion (Spread)
  * Standard deviation (sd)
  * Variance (Var) or coefficient of variation

\pause

* Measures of shape
  * Skewness, modality



!split
===== Histograms =====

 * Task 1: make a histogram from a 2d random distribution
 * Task 2: make a 2d heat map from a 2d random distribution


!split
===== Frequency plots and Histograms =====
Given a set of data

o Look for min and max values
o Divide the range of values into a number of sensible class intervals (bins)
o Count
o Make a frequency table (or percentage)
o Plot (see jupyter notebook)

\pause

!bblock Does this histogram represent uncertainty?
No. It shows variability, but it can be used to quantify uncertainty.
!eblock

 
!split
===== Class widths =====
* Class widths (bin sizes) are usually CONSTANT
  * the height of each bar is proportional to the number of values in it
* If class width are VARIABLE
  * the AREA of each bar is proportional to the number of values in it
* For small samples, the shape of the histogram can be very sensitive to the number and definition of the class intervals

\pause

!bblock Exercise
Plot a histogram from different random number distributions and bin sizes.
!eblock


!split
===== Cumulative Histogram =====

* Cumulative frequency

* Each data point can be plotted individually

* It helps to read quantiles and compare distributions

* Practice with your jupyter notebook

 
!split
===== Measure of Location: Central Tendency, MEAN =====
 
!bt
\centering $m_x = \  <x> \  = \ \bar x \ = \frac{1}{n} \sum^n_{i=1} x_i$
!et

\pause

Each point weighted equally by $\frac{1}{n}$ (assumption)

\pause

* Every element is the data set contributes to the values of the mean
* An average provides a common measure for comparing one set of data to another
* The mean is influenced by the extreme values in the data set
* The mean may not be an actual element if the dataset
* The sum of all deviation from the mean is zero, and the sum of squared deviation is minimized when those deviations are measured from the mean



 
!split
===== Means =====
* Arithmetic
  * Mean of raw data
 
!bt
\centering $\frac{1}{n} \sum^n_{i=1} x_i$
!et

\pause

* Geometric
  * $n^{th}$ root of product
!bt
\centering $ \left( \prod^n_{i=1} x_i \right)^{\frac{1}{n}} $
!et
* Geometric
	* Mean of logarithms
!bt
\centering $ exp \left( \frac{1}{n} \sum^n_{i=1} ln(x_i) \right) $
!et

\pause

* Harmonic
  * Mean of inverses
!bt
\vspace{-4em}
\begin{center}
$ \left( \frac{1}{n} \sum^n_{i=1} \frac{1}{x_i} \right)^{-1}$
\end{center}
!et


!split
===== Median =====
@@@CODE ../code/median.py

* On a cumulative density plot, the value of the x-axis that corresponds to 50 \% of the y-axis
* Not influenced by extreme values
* May not be contained in the dataset (if n is even)
* For a perfectly symmetrical dataset, means = median



!split
===== Mode =====
* The mode is the most frequently occurring data element or the most likely or most probable value (for a pmf)
* A data set may have more than one mode and it thus called multimodal
* A mode is always a data element in the set
* For a perfectly symmetrical dataset, means = median = mode



!split
===== Distribution Descriptors =====
FIGURE: [../figures/mode, width=600 frac=1.0]



!split
===== Quantiles =====
!bblock Quartiles
The data split into quarters.
!eblock

\pause
!bblock Deciles
The data are split into tenths. The fifth decile is also the median.
!eblock

\pause
!bblock Percentiles
The data are split into hundredths.  P10, P25, P50, P75 and P90 are the most commonly used.
!eblock

\pause
!bblock Quantiles
A generalization of splitting data into any fraction
!eblock
 

!split
===== Distribution Descriptors =====
FIGURE: [../figures/quant, width=600 frac=1.0]


!split
===== Dispersion (Spread) =====
!bblock Range
!bt
\centering  R = maximum - minimum
!et
!eblock


!bblock Inter-quantile Range
!bt
\centering  IQR = Q3 - Q1
!et
!eblock


!bblock Mean Deviation from the Mean
!bt
\centering  MD = $\sum^n_{i=1} (x_i - \bar x)/n$
!et
!eblock

!bblock Mean Absolute Deviation
!bt
\centering  MAD = $\sum^n_{i=1} |x_i - \bar x|/n$
!et
!eblock


!split
===== Variance =====

The variance is the average of squared differences between the sample data points and their mean

!bblock Variance
!bt
\centering  $s_x^2 = \frac{1}{n} \sum^n_{i=1} (x_i - \bar x)^2$
!et
!eblock


!bblock Standard Deviation (SD)
!bt
\centering  $s_x = \sqrt{\frac{1}{n} \sum^n_{i=1} (x_i - \bar x)^2}$
!et
!eblock


!split
===== Standard Deviation =====
FIGURE: [../figures/sd, width=600 frac=1.0]

!split
===== Standard Deviation =====
FIGURE: [../figures/sd2, width=600 frac=1.0]



!split
===== Measures of dispersion =====
!bblock Standard Deviation (SD)
!bt
\centering  $  SE_x = \frac{s_x}{\sqrt{n}}$
!et
!eblock

!bblock Coefficient of Variability
!bt
\centering  $CV = \frac{s_x}{\bar x}$
!et
!eblock


!split
===== Modality =====
* Unimodal
* Bimodal
* Polymodal

FIGURE: [../figures/multimode, width=600 frac=0.7]

!split
===== Skewness =====
It measures the symmetry in a distribution

!bt
\centering  $Sk = \frac{\frac{1}{n} \sum^n_{i=1} (x_i - \bar x)^3}{s^3}$
!et

FIGURE: [../figures/skness, width=600 frac=1.0]


A bit out of fashion with ML


!split
======= Distributions =======

!split
===== Distribution Models =====
!bblock Distribution
means of expressing uncertainty or variability
!eblock

Models
* Uniform: useful when only upper and lower bounds are known
* Triangular: useful when estimates of min, max, mode [P10, P50, P90] are available
* Normal: symmetric model of random errors or unbiased uncertainties with mean of standard deviation specified
  * very common for observed data
  * additive processes tend to be normal as a result of the Central Limit Theorem
* log normal comes from multiplicative uncertainties with mean and standard deviation specified



!split
===== Uniform Distribution =====
* The uniform distribution is useful as a rough model for representing low states of knowledge when only the upper and lower bounds are known.
* All possible values within the specified maximum and minimum values are equally likely (b=max, a=min):
* It can express maximum uncertainty

!bblock PDF: $f(x) =$
!bt
$/frac{1}{b-a}, a \leq x \leq b $
!et
!eblock


!bblock CDF: $ F(x) = $
!bt
$/frac{x-a}{b-a} $
!et
!eblock


Notation: $ X  \sim U(a, b)$



!split
===== Uniform Distribution =====

FIGURE: [../figures/uniform, width=600 frac=1]



!split
===== Triangular distribution =====
* The triangular distribution can be used for modeling situations, where non extremal (central) values are more likely than the upper and lower bounds.

* Take min, mode and max as inputs. Typically on the basis of subjective judgement:

!bblock PDF: $f(x) =$

!bt
 $  \frac{2 (x-a)}{(b-a)(c-a)}; \ \text{if}\ a \leq x \leq c $
 
 $  \frac{2 (b-x)}{(b-a)(c-a)}; \ \text{if}\ c \leq x \leq b $
!et
!eblock

!bblock CDF: $ F(x) = $
 
!bt
 $  \frac{(x-a) ^2 }{(b-a)(c-a)}; \ \text{if}\ a \leq x \leq c $
 
 $  1 - \frac{(b-x)^2}{(b-a)(c-a)}; \ \text{if}\ c \leq x \leq b $
!et
!eblock



!split
===== Triangular Distribution =====

Notation: $ X  \sim T(a, b, c)$

FIGURE: [../figures/triangolar, width=600 frac=1]


It can be symmetric or asymmetric



!split
===== Normal Distribution =====
* The normal distribution ('bell curve' or Gaussian) for modeling unbiased uncertainties and random errors of the additive kind of symmetrical distributions of many material processes and phenomena.
* A commonly cited rational for assuming normal distribution is the central limit theorem, which states that the sum of independent observations asymptotically approaches a normal distribution regardless of the shape of the underlying distributions(s=


!bblock PDF:
!bt
$f(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} exp \left\{ -\frac{1}{2} \left( \frac{x - \mu}{\sigma} \right) ^2 \right\}; \ - \infty \leq x \leq \infty $
!et
!eblock


!bblock CDF: $ F(x) = $
has no closed form solution but is often presented using the complementary error function solution
!eblock




!split
===== Normal Distribution =====

Notation: $ X  \sim G(\mu, \sigma)$

!bblock
It is a Symmetric distribution around the mean
!eblock

$\mu$ is the mean, $ \sigma $ is the standard deviation

$\mu \pm \sigma : 68.3 \% probability $

$\mu \pm 2 \sigma : 95.4 \% probability $

$\mu \pm 3 \sigma : 99.7 \% probability $

!split
===== Normal Distribution =====
FIGURE: [../figures/normal, width=600 frac=0.8]




!split
===== Data transformations =====
* Often, it is useful to transform a sample distribution into the space of an equivalent normal distribution, where many statistical operations can be easily performed and visualized
* The approach involves a rank-preserving one-to-one transformation.
* Transforming the data so that their distribution matches a prescribed (target) distribution.
* Sometimes we must transform the data...

!split
===== Normal Score Transformation =====

o From data to cumulative distribution.

o From cumulative distribution and map back.
 

FIGURE: [../figures/nst, width=600 frac=0.8]

The analysis can be performed on the gaussian distribution, and then moved back to the original distribution

 
 





