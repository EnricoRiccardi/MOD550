!split 
===== Let me first introduce US =====
!bslidecell 00
Enrico Riccardi

email: enrico.riccardi@uis.no
!eslidecell
!bslidecell 01
FIGURE: [../figures/enrico_riccardi, frac=0.22]
!eslidecell




!bslidecell 10
Reidar Bratvold

email: reidar.bratvol@uis.no
!eslidecell
!bslidecell 11
FIGURE: [../figures/reidar_brumer_bratvold, frac=0.22]
!eslidecell


!bslidecell 20
Remus Gabriel Hanea

email: rhane@equinor.com
!eslidecell
!bslidecell 21
FIGURE: [../figures/remus_gabriel_hanea, frac=0.22]
!eslidecell



!split 
===== Let me first introduce myself =====
!bslidecell 00
Enrico Riccardi
email: enrico.riccardi@uis.no
office: KE-E-301B
!eslidecell

!bpop
=== Before to be here... ===
* Chemical engineer graduated from the Politecnico di Torino
* PhD at M$\&S$T university of Rolla, Missouri, USA
* Post Doc at TUD Darmstadt, Germany
* Researcher at NTNU, Trondheim, Norway
* Post Doc UiO, Oslo, Norway
* Assoc. Prof. at Uis, Stavanger, Norway


!bslidecell 01
FIGURE: [../figures/torino, width=200 frac=1.0]
!eslidecell

!epop

!split
===== Course objectives =====
!bblock
Understanding of
!eblock
!bpop
* data sources and consequent data properties.
* data analysis/machine learning approaches outcomes.
* sensitivity analysis
* predictive modeling
* multivariate data analysis
* machine learning techniques application
* visualization and reporting
!epop

!split
===== Teaching method =====
_!Active Learning!_

There will be a combination of (old school) lectures.

Tutorial and hands-on will be presented during the course. 

Study groups are strongly encouraged.

Discussions are encouraged at any stage. 


!split
===== Python =====
The tutorials and hands on will be mostly based on python.

An introduction to python will be provided during the course. Yet, this is not a Python programming course! 

Git repository



!split
===== A personal consideration on generative AI =====
!bblock
With great power comes great responsability (Spider-Man)
!eblock

LLMs can and shall be used. As their development is surging in the last years, their help
in writing code and reports is undeniable. Studends shall learn how to master these tools. 
Yet, while their usage is encouraged, the risk of excessevily rely on them could hinder learning.

Students, if they want to be students (i.e. learn), are encouraged to take the responsability to deliver original
output.


!split 
===== Why are we here? Why this course? =====
* Decisions are the hinge. What influences your decisions has value.

!bpop
!bblock
* Better results come from better decisions. \\
    color{blue}{*STATISTICAL argument*}

* Machine learning can be useful color{red}{ONLY} when it helps taking better decisions.
!eblock
!epop

!split
===== Decions, decisions, decisions... =====

!bblock Life lesson?!
Life is a sum of all your choices (Albert Camus)
!eblock

\vspace{2em}

!bpop

!bslidecell 00
The only way you can purposefully influence your life, your family, your
organization, your country or your world is through color{red}{the decisions you make}.
!eslidecell 

!bslidecell 01
FIGURE: [../figures/decisions, width=200 frac=0.8]
!eslidecell

!epop

!split
===== Uncertainity is fed to decions =====

!bpop

FIGURE: [../figures/Decisionquality, width=200 frac=0.3]

\vspace{-1em}

* In this course we will learn to use data and models (ML) to make better decisions. 
* Each application will be a mere exercise of the concepts we will here introduce.

\vspace{-1em}

!bblock Do not try this at home!
* color{red}{Please Do not use a technical approach for love matters.}
!eblock

!epop


!split
===== Uncertainity =====
It is present in every stage of life (at each decision).

You woud thus need to:
!bpop
o Rationalize uncertainity (qualify)
o Quantify uncertainity
o Make decisions under uncertainity
o Operate under uncertainity

!epop

!split
===== Uncertainity or Probability? =====

Our aim here is to provide a good guidance how to link data, models and output to value creation.

!bpop
* First we need to understand uncertainity and probability, and the difference between the two.

!bblock
* Spoiler: Probability is the language of uncertainity!
!eblock

\vspace{1em}

* We will analyse, quantify and structure models as a function of uncertainity.

* Clarity of language in probability is one of the hallmarks of decision analysis
!epop



!split
===== Data properties =====

* All starts from data: what are data-properties?

!bpop
* Are there such things as good data and bad data?

!bblock Life lesson (or exam question, same thing ;) )
* Data color{red}{ DO NOT always} have value.
!eblock

\vspace{1em}

* TRASH in TRASH out

!epop

!split
===== Spatial and Temporal Data =====

Statistics is collecting, organizing, and interpreting data
!bpop

Spatial and temporal statistics is a branch of applied statistics that
emphasizes 
o the context of the data, 
o the spatial and time dependent relationship between data
o the different relative value and precision of the data.
!epop


!split
===== Hard and soft modeling =====

Models allow us to predict ’the future’, or describe the past and
present (what is the present...?)

\vspace{1em}

!bpop
!bblock Last life lesson for today
Models are always wrong, but some are userful. (George Box)
!eblock
!epop

\vspace{2em}

!bpop
=== Three main families: ===
o Hard models (physics)
o Soft models (statistic)
o Machine learning
!epop

!split
===== Hard modeling =====
!bpop

* Based on an accurate physical description of the system and mathematical modeling (e.g. differential equations). Hard models are often deterministic.

* Hard modeling methods usually use optimization methods to find out the best values for the parameters of the model.

* Hard modeling is preferable in laboratory experiments, where all the variables are controlled and the physicochemical nature of the dynamic model is known and can be fully described using a known mathematical model.

* Hard modeling, if successful, usually gives better understanding of a system and better extrapolations. Wrong assumptions often leads to non-sense results.
!epop

!split
===== Soft modeling =====

!bpop
* Soft-modeling describes systems without the need of an *a priori* physical or (bio)chemical model postulation. They are _data driven_ models.

* Soft models are much easier to make than hard models.

* Soft modeling can be used to understand complex relationships.

* Soft modeling needs (much) more data than hard-modeling.

* Soft models have a poor extrapolating capabilities (compared with hard-modeling)
!epop


!split
===== How to create hard models? =====
After understanding the problem to be solved we need to:

o Link mathematics to physics.
o Define boundary conditions and constitutive equations.
o Make tons of assumptions.
o Solve the constitutive equation in space and time.
o Check solution stability and sensitivity analysis.
o A long set of judicious approximations have to be taken.
o It is hard (but we are engineers!).
o Get quite some money for the awesome job.


!split
===== How to create soft models? =====

After understanding the general problem to be solved we need to:

* Determine a suitable _numerical description_ .
* Choose a suitable _model_ to which parameters are fitted.
* Train, test, validate the model.
* Perform _data analysis_ with chosen method(s).
* Link predictions with expectations.


!split
===== Spatial and Temporal Modeling =====

!bblock
It is a branch of statistical analysis and model that uses spatial and time dependent data.
!eblock
!bpop
* Only a subset of statistical models can be fed with time dependent data
(most standard statistical method assume independent, identically distributed, data)

* Spatial and time related data come at a different range of scales
Frequency of data collection can be dependent of time and space,
resulting into different rappresentativity of a sample.
!epop


!split 
===== Quantifying uncertainty =====
!bblock
On the data sources side
!eblock
* Confidence intervals
!bpop
* Relevance
* Significance
* Correlation
* Causation
* Data Filters
* Biases identification
!epop

!split 
===== Quantifying uncertainty =====
!bblock
On the modelling side
!eblock
!bpop
* Regression
* Principal components
* Decision tree (random forests)
* Neural network
* Clustering
* Performance metrics
!epop

!split
===== Fields of application =====
* Spatial estimation of energy and mineral resources
!bpop

* Weather modeling: from aviation to agriculture
* Maintenance forecasting 
* Commodity, currency, stock and financial markets
* Market analysis
* Risk analysis
* ... and much much more!
!epop

