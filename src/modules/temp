!split
======= Statistics =======

!bblock Definition
Statistics is the science of acquiring and utilizing data
!eblock

!bpop
* It comprises tools for data collection, summarization, and interpretation.

* The aim is identifying the underlying structure, trends, and relationships inherent in the data.

* Is it all statistics then? Yes.

* _Numbers to data, data to information_
!epop



!split
===== Data properties =====
Before we talk about machine learning, we need to refresh some terminology.

!bpop
!bblock Population
The universe of all possible outcomes and events.
!eblock

!bblock Sample
A finite subset extracted from the population.
!eblock

!bblock Exhaustivity
The samples covered the population spectra.
!eblock

!bblock Representativity
The population is properly described by the samples.
!eblock
!epop


!split
===== Big data =====
We speak of big data when dataset are very large: i.e. many instances and features
Models have thus a large set of parameters (and often no one has a clue anymore of what is going on).

!bpop
* Volume of data
* Variety different types of data sources with different length and scale.
* Frequency of data generation
!epop


!split
===== Sampling =====

Samples shall have no bias (to be randomly selected). If not, the bias has to be corrected for.
!bpop
!bblock Cycle of data
o Data is collected
o Checked upon
o Some modelling
o Analysis and visualization
o AnOmLiEs and outliers detection (exclusion?)
!eblock
!epop

!split
===== Data expectation =====

FIGURE: [../figures/data, width=600 frac=0.8]


!split
===== Data quality =====

o Data has to be acquired and integrated
o Data are passed to a quality analysis and control
o Data cleaning, consistency check. Most of time goes here


xxx missing something xxxx

!split
===== Modeling =====
* Predictive modeling (supervised learning)
Hunt for redundancy
Reduce dimensionality

* Complicated is not sophisticated... Linear regression is a type of supervised learning

* The model can be used to guide data acquisition (risky!)

* Machine learning enters here. It improves the *old* statistical analysis


!split
===== Visualization and reporting =====
* The data has to be condensed into a visualization to provide input for decisions.
* Depending on the goal, very very different visualizations are possible.
* Use a model to indicate what is undersampled or oversampled.


!split
===== Exploratory data analysis =====

!bblock Summarizing and visualizing data as a starting point for more analysis later on.

* Computing summary statistics (e.g. means and variance)
* Determining conditional probabilities of cause+effect relationships
* Calculating correlation and rank correlation coefficient between two variables
* Visualizing univariate, bivariate and multivariate data
* Estimating probability coverage levels for different distributions
* Analyzing behaviour of normal and lognormal distributions
* Calculating confidence interval and sampling distribution for the mean
* Testing for significance of difference in means
* Comparing two different distributions for statistical equivalence 
* Developing a nonparametric regression model from given data
* Reducing data dimensionality  
* Grouping data   

!eblock


!split
===== Random Variables =====
* A random variable is a real valued function that assigns a value to each outcome in the sample space
* A random variable (RV) can be either discrete or continuous
  * Discrete RV:
  * Continuous RV

* The probability mass function (PMF),p, of a discrete RV, X, denotes the probability that the RV is equal to a specified value, a.

p(a) = p(X = a)

* Similarly, the cumulative distribution function (CDF), F, denotes the sum

!bt 
$CDF = \int^{\inf}_{-\inf} f(x) dx$
!et






!split
===== Sampling aim =====
* What are the effective sampling ,methods for predict the maintenance of wind turbine blades
(Time series?)

* How to sample and analyze Solar Panels fo determine the efficiency of the source
(Usage patterns, energy production forecast)


!split
===== Sampling approaches =====
* Sampling with replacement
  * The number of the members of the population does not change

xxx missing
* Sampling without replacement
 

!split
===== Examples =====
Pandas table

Goal of the analysis:
* Data interpretation
What does the number actually mean? And how do the different variables correlate?

* Data quality vs data cleaning
What are the error sources?

* Condense information (is the mean sufficient?)
We need to remove all unnecessary data without losing too much information.


!split
===== Univariate statistics =====
* Displaying data:
	histogram, frequency plots, cumulative

* Measures of Location
  Mean median mode
  * Quartiles, Percentiles, Quantiles

* Measure of Dispersion (Spread)
   MAD, standard deviation (sd), variance (Var), coefficient of variation

xxx missing

!split
===== Histograms =====

Sample table

Python code

!split
===== Frequency plots and Histograms =====
Given a set of data

o Look for min and max values
o Divide the range of values into a number of sensible class intervals (bins)
o Count
o Make a frequency table (or percentage)
o xxx missing

!split
===== Example =====
a table
note: way too fast on the board

plot histogram: use vanilla, pandas, matplotlib

Does this histogram represent uncertainty?
No. It shows variability, but it can be used to quantify uncertainty.

!split
===== Class widths =====
* Class widths (bin sizes) are usually CONSTANT
  * the height of each bar is proportional to the number of values in it
* If class width are VARIABLE
  * the AREA of each bar is proportional to the number of values in it
* For small samples, the shape of the histogram can be very sensitive to the number and definition of the class intervals

!split
===== Sensitivity =====
Plot with different bin sizes.
This could be a fun exercise to lear python

xxx exercise xxx


!split
===== Cumulative Histogram =====

* Cumulative frequency

* Each data point can be plotted individually

* It helps to read quantiles and compare distributions

* Python code to get it?

!split
===== Measure of Location: Central Tendency, MEAN =====

formulat
$m_x = <x> = xbar = 1/n sum $

if the data represent a random sample, each poit weighted equally by 1/n

* Every element is the data set contributes to the values of the mean
* An average provides a common measure for comparing one set of data to another
* THe mean is influenced by the extreme values in the data set
* The mean may not be an actual element if the dataset
* The sum of all deviation from the mean is zero, and the sum of squared deviation is minimized when those deviations are measured from the mean

 

!split
===== Mean means =====
* Arithmetic
  Mean of raw data

* Geometric
  $n^{th}$ root of product
  mean of logarithms

* Harmonic
  Mean of inverses


!split
===== Mediam =====
* The central value in a data set when the data points are put in ascending or descending order

median =formula odd/even

Average xxxmissing

!split
===== Mode =====
* The mode is the most frequently occurring data element
or the most likely or most probable value (for a pmf)

* A data set may have more than one mode and it thus called multimodal

xxx

!split
===== Examples of different distributions =====

normal, symmetrical, asymmetrical, multimodal, skewed
Mode != Median != Mean

!split
===== Quantiles =====
* Quartiles: As median splits data into two halves, the quartiles psli the data into quarters

* Deciles

* Percentiles
- splits the data into hundredths

* Quantiles
are a generalization of splitting data into any fraction

!split
===== From CDF to Quantiles =====

plot

make a cdm, draw the quartiles. Quantiles are on the x. The percentiles are on the y.

nice plot here

!split
===== Dispersion (Spread) =====
* Range

R = maximum - minimum

* Inter-quantile Range

IQR = Q3 - Q1

* Mean Deviation from the Mean?

MD = sum

* Mean Absolute Deviation

MAD = sum


!split
===== Variance and Standard Deviation =====
Variance is the average of squared differences between the sample data points and their mean

Variance  $s_x^2 = /fract{1}{n} formula

Standard Deviation formula


!split
===== Standard deviation =====
$sd = \sqrt{Var}$ : average squared difference from the mean

Plot with
1 sd distance : normal distribution 1sd covers 2/3 of data
1 sd: 68\%
2 sd: 95\%
3 sd: 99.7\%



!split
===== Variance of the mean =====
xxx plots

!split
===== Effect of Sample size (random sample): Standard Error (SE) of the mean =====
Central limit theorem: the more sample I have, the more 'sure' I am

SE_x

!split
===== Coefficient of Variability =====

A bit out of use

CV = Sx/X

* A CV of greater than 1 can

xxx

!split
===== Discrete and continuous CDF =====

* Discrete CDF
For a discrete RV that attains values $x_1, x_2, ... $

summation

nice eqs
nice plots

* Continuous CDF

integral


!split
===== Discrete PMF and Continuous PDF =====

!split
=== Discrete PMF ===
plots and functions


!split
=== Continuous PDF ===
The PDF f(x) is a non-negative function that characterized the relative probability (frequency of occurrence) of realization values for a RV at a neighbourhood of a point

eq and plots
 

!split
===== Empirical PMF (from data) =====
o Sort the data points in an ascending order such taht x_1 < x_2 ...

xxx

!split
===== PMFs and CDFs =====

Symmetric, Right-Skewed, Left-Skewed

plots

!split
===== Measure of Shape: Modality =====
Number of Modes: unimodal, bimodal, polymodal

plots

!split
===== Measure of Shape: Skewness =====
Measure of symmetry in the distribution of the data values

Sk = /fract{/fract{1}{n}/sum{n}{i=n}

a bit out of fashion with ML
xxx

!split
===== Measure of Shape: Kurtosis =====
Measures the 'flatness'

a bit out of fashion with ML


!split
===== Example: python on data =====

pd.summary()

!split
===== Box Plots =====

plot


!split
===== Summary =====
* Mean
* Variance
* Standard deviation
* Median
* Mode
* lost: the other


!split
======= Distributions =======
Distributions: means of expressing uncertainty or variability
Emp


!split
===== Distribution Models =====
* Uniform: useful when only upper and lower bounds are known
* Triangular: useful when estimates of min, max, mode [P10, P50, P90] are available
* Normal: symmetric model of random errors or unbiased uncertainties with mean of standard deviation specified
* very common for observed data
* additive processes tend to be normal as a result of the Central Limit Theorem
* log normal comes from multiplicative uncertainties with mean and standard deviation specified

!split
===== Central Limit Theorem =====

buh

!split
===== Uniform Distribution =====
* The uniform distribution is useful as a rough model for representing low states of knowledge when only the upper and lower bounds are known.
* All possible values within the specified maximum and minimum values are equally likely (b=max, a=min):
PDF f(x) = /fract{1}{b-a}, a=<x=<b
CDF:
Moments:
Notation: X \pf U(a, b)

plots

!split
===== Example =====
Wind turbine example

!split
===== Solution =====

!split
===== Triangular distribution =====
* The triangular distribution can be used for modeling situations, where non extremal (central) values are more likely than the upper and lower bounds.

* Taeke min, mode and max as inputs. Typically on the basis of subjective judgement:

PDF: f(x)

CDF:

Moments:

It can be symmetric or asymmetric


!split
===== Normal Distribution =====
* The normal distribution ('bell curve' or Gaussian) for modeling unbiased uncertainties and random errors of the additive kind of symmetrical distributions of many material processes and phenomena.
* A commonly cited rational for assuming normal distribution is the central limit theorem, which states that the sum of independent observations asymptotically approaches a normal distribution regardless of the shape of the underlying distributions(s=

PDF: f(x)
CDF: F(x) has no closed form solution but is often presented using the complementary error function solution
Ã† It can also be expressed in terms of the stands normal CDF, G()
F(x) = G{/fract{x-/mu}{7sigma} = G(z)

xxx

!split
===== Probability Levels - Normal distribution =====

Plot
!split
===== Examples of Normal Distribution - PDF =====
nice plot

!split
===== Normal Distribution =====
* The CDF, F(x), has no closed form solution and is expressed in terms of the standard normal CDF, G()
F
 where z =
Note that z is a dimensionless variable with zero mean and unit variance

$z= /fract{}{}$

with the quantile, q, being used as an approximation of the cumulative probability, F

more elegantly, that can be expressed as $ x =/mu + /sigma G^{-1}(q) = /mu + /sigma z $
* The inverse normal CDF, or the z-score, can be calculated using:
python scipy  norm.ppf(z, loc=0, scale = 1)



!split
===== Exercise =====
Given a xxx distribution, determine the 95\%


!split
===== Normal distribution =====
python script

!split
===== Data transformations (?!) =====
* Often, it is useful to transform a sample distribution into the space of an equivalent normal distribution, where many statistical operations can be easily performed and visualized
* THe approach involves a rank-preserving one-to-one transformation, as chemically.
* Transforming the data so that their distribution matches a prescribed (target) distribution
* SOmetimes we must transform the data...

!split
===== Normal Score Transformation =====

o From data to cumulative distribution.

o From cumulative distribution and map back.

plot

The analysis can be performed on the gaussian distribution, and then moved back to the original distribution


!split
===== Normal Score Transformation =====
For any given values, xi of the original variable, the empirical cumulative probability of quantile q is set equal to


!split
===== Log - Normal distribution =====
For a lognormal distribution, we define the standard normal variate as

$ \alfa = means \ of \ ln(x) $
$ \beta = SD \ of \ ln(x) $


$F(x) = G { } = G(z)$
$z = \fract{ln(x) - \alpha}{\beta}$

* Graph of ln(x) versus G-1(q) should yeld straight line with


!split
===== Log - Normal Distribution =====
* Working with lognormal distributions involves

* The following relationship are useful in this context

